{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb9a8f90cb9235cc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Wavelet and orientation\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook is the code that is used to study the impact on wavelet-based radiomics model performance caused by differences in orientation of the inputs in the training and testing data. The motivation of the study is to identify potential issues of current radiomics pipeline that considered wavelet decomposition as an ordinary filter. The authors argue that a robust radiomics model should be independent of the input orientation\n",
    "\n",
    "## Workflow of study\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    Input[(Input)] --> train_cohort[(Training set)] & test_cohort[(\"Testing set (R_0)\")]\n",
    "    test_cohort --> aug(Augmentation) --> aug_sets[(\"R_10, R_20, R_40, R_80\")]\n",
    "    \n",
    "```\n",
    "\n",
    "## Required packages\n",
    "\n",
    "* numpy\n",
    "* scipy\n",
    "* SimpleITK\n",
    "* pandas\n",
    "* mnts (https://github.com/alabamagan/mri_normalization_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:20:35.166990800Z",
     "start_time": "2023-08-09T14:20:35.125831800Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Numpy version': '1.26.4',\n",
       " 'Scipy version': '1.13.0',\n",
       " 'SITK version': '2.3.1',\n",
       " 'Pandas version': '2.2.2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.spatial import transform\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from typing import Iterable, List, Optional, Tuple\n",
    "from IPython.display import *\n",
    "\n",
    "# Used to ensure repeatability\n",
    "global_rand_seed = 285758975\n",
    "\n",
    "# define for easy usage\n",
    "mdprint = lambda x: display(Markdown(x))\n",
    "\n",
    "# add package to path without installing it\n",
    "sys.path.append(\"/home/user/Source/Repos/wavelet_analysis/src\")\n",
    "\n",
    "from feature_robustness_analysis.rot_aug.im_ops import *\n",
    "from feature_robustness_analysis.rot_aug.rot_ops import *\n",
    "\n",
    "# List out the version of the packages required\n",
    "np_ver = np.__version__\n",
    "sp_ver = scipy.__version__\n",
    "sitk_ver = sitk.__version__\n",
    "pd_ver = pd.__version__\n",
    "display({\n",
    "    'Numpy version': np_ver, \n",
    "    'Scipy version': sp_ver, \n",
    "    'SITK version': sitk_ver,\n",
    "    'Pandas version': pd_ver\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18120452520f78a3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Processing NSCLC public data\n",
    "\n",
    "The CT public dataset is downloaded from TCIA database. We convert all the DICOM files of the CT from Aert. et al's data set into Nifty format first. The segmentation was extracted using the software package they recommend. **Note that intensity normalization was already conducted prior to this notebook. Please see manuscript supplmentary for more details.** \n",
    "\n",
    "The extracted patches, including those from the original CT, from the segmentation and the rotated version, are available on request, which is roughly 30GB in size stored in an .iso file. \n",
    "\n",
    "## Handling samples with multiple lesions\n",
    "\n",
    "There are several patients with multiple lesions and this study consider each lesion a single data point. Patients with mulitple lesions are identified using the `ConnectedComponentFilter`, with a minimal threshold of 30 pixels to remove clutters. In addition, lesions with only 1 axial slices (3mm in thickness) is also removed from analysis to avoid over interpretation with 3D features. \n",
    "\n",
    "## Excluded\n",
    "\n",
    "* Case LUNG1-128 is excluded because segmentation is not available\n",
    "* Case LUNG1-245 is excluded because of mismatch in data dimension and segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb4329033d10592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:20:48.492991700Z",
     "start_time": "2023-08-09T14:20:48.482026600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from mnts.utils.filename_globber import *\n",
    "\n",
    "'''Configurations'''\n",
    "data_root = Path(\"/media/storage/Data/NSCLC/\")  # this is where the Nifity files were stored\n",
    "img_dir = data_root.joinpath(\"02.Normalized_Images/ZScore\")\n",
    "seg_dir = data_root.joinpath(\"0B.SEGMENT_ALL/GTV-1\")\n",
    "idregpat = \"^([\\w\\d]+-\\d+)\" # For pairing the IDs\n",
    "\n",
    "# exclude list\n",
    "exclude_pids = ['LUNG1-128', 'LUNG1-246']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6db507ef19d960",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Paring the images and segmentation\n",
    "\n",
    "Using `mnts` methods, the original NSCLC data were converted to NIFTI files. The naming system was based on the patient\n",
    "code \"LUNG1-XXX\". The segmentation was saved in the same format as well, and they are paired by using `re` package.\n",
    "\n",
    "## Calculating the center of mass\n",
    "\n",
    "The images are first cropped into 3D patches encapsulating a single lesion. There could be multiple lesions per patient.\n",
    "Therefore, we first found out how many lesions there are by looking at the connected components. Then, the center of \n",
    "mass of each lesion are computed as coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de4e617d9fb379b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:24:54.050858700Z",
     "start_time": "2023-08-09T14:21:43.312794400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-09 22:21:45,184-INFO] (global) Loging to /media/storage/Source/Local/ipython/tmp66ytefrm.log with log level: 20\n",
      "[2023-08-09 22:21:45,185-INFO] (global) Created first logger. Exception hooked to this logger. Log level is: info\n",
      "[2023-08-09 22:21:45,185-INFO] (default) Loging to /media/storage/Source/Local/ipython/tmp66ytefrm.log with log level: 20\n",
      "[2023-08-09 22:21:45,185-INFO] (default) Requesting logger [algorithm.utils] not exist, creating...\n",
      "[2023-08-09 22:21:45,185-INFO] (algorithm.utils) Loging to /media/storage/Source/Local/ipython/tmp66ytefrm.log with log level: 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Images</th>\n",
       "      <th>Segmentations</th>\n",
       "      <th>COM</th>\n",
       "      <th>Number of lesions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LUNG1-001</th>\n",
       "      <td>LUNG1-001-Missing+0.nii.gz</td>\n",
       "      <td>LUNG1-001-Segmentation+300_GTV-1.nii.gz</td>\n",
       "      <td>[((82.30074532053526, -201.48105435025894, -45...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LUNG1-002</th>\n",
       "      <td>LUNG1-002-Missing+1.nii.gz</td>\n",
       "      <td>LUNG1-002-Segmentation+300_GTV-1.nii.gz</td>\n",
       "      <td>[((-74.47025678716594, 16.355618635968504, -18...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LUNG1-003</th>\n",
       "      <td>LUNG1-003-Missing+1.nii.gz</td>\n",
       "      <td>LUNG1-003-Segmentation+300_GTV-1.nii.gz</td>\n",
       "      <td>[((47.42720699680901, -2.4607800757946747, -12...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LUNG1-004</th>\n",
       "      <td>LUNG1-004-Missing+0.nii.gz</td>\n",
       "      <td>LUNG1-004-Segmentation+300_GTV-1.nii.gz</td>\n",
       "      <td>[((59.82698099398604, 80.81240635855703, -557....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LUNG1-005</th>\n",
       "      <td>LUNG1-005-Missing+1.nii.gz</td>\n",
       "      <td>LUNG1-005-Segmentation+300_GTV-1.nii.gz</td>\n",
       "      <td>[((-58.78786734478716, 5.099882393388968, -15....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LUNG1-418</th>\n",
       "      <td>LUNG1-418-Missing+0.nii.gz</td>\n",
       "      <td>LUNG1-418-Segmentation+300_GTV-1.nii.gz</td>\n",
       "      <td>[((57.32439171943225, -145.95976964605273, -40...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LUNG1-419</th>\n",
       "      <td>LUNG1-419-Missing+0.nii.gz</td>\n",
       "      <td>LUNG1-419-Segmentation+300_GTV-1.nii.gz</td>\n",
       "      <td>[((-76.55753803907983, -207.93668661304113, -4...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LUNG1-420</th>\n",
       "      <td>LUNG1-420-Missing+0.nii.gz</td>\n",
       "      <td>LUNG1-420-Segmentation+300_GTV-1.nii.gz</td>\n",
       "      <td>[((54.15286421869259, -121.5744590908783, -519...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LUNG1-421</th>\n",
       "      <td>LUNG1-421-Missing+0.nii.gz</td>\n",
       "      <td>LUNG1-421-Segmentation+300_GTV-1.nii.gz</td>\n",
       "      <td>[((59.817097819498265, -168.61503094308367, -4...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LUNG1-422</th>\n",
       "      <td>LUNG1-422-Missing+0.nii.gz</td>\n",
       "      <td>LUNG1-422-Segmentation+300_GTV-1.nii.gz</td>\n",
       "      <td>[((-26.546376208612504, -145.0336046886111, -4...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Images   \n",
       "LUNG1-001  LUNG1-001-Missing+0.nii.gz  \\\n",
       "LUNG1-002  LUNG1-002-Missing+1.nii.gz   \n",
       "LUNG1-003  LUNG1-003-Missing+1.nii.gz   \n",
       "LUNG1-004  LUNG1-004-Missing+0.nii.gz   \n",
       "LUNG1-005  LUNG1-005-Missing+1.nii.gz   \n",
       "...                               ...   \n",
       "LUNG1-418  LUNG1-418-Missing+0.nii.gz   \n",
       "LUNG1-419  LUNG1-419-Missing+0.nii.gz   \n",
       "LUNG1-420  LUNG1-420-Missing+0.nii.gz   \n",
       "LUNG1-421  LUNG1-421-Missing+0.nii.gz   \n",
       "LUNG1-422  LUNG1-422-Missing+0.nii.gz   \n",
       "\n",
       "                                     Segmentations   \n",
       "LUNG1-001  LUNG1-001-Segmentation+300_GTV-1.nii.gz  \\\n",
       "LUNG1-002  LUNG1-002-Segmentation+300_GTV-1.nii.gz   \n",
       "LUNG1-003  LUNG1-003-Segmentation+300_GTV-1.nii.gz   \n",
       "LUNG1-004  LUNG1-004-Segmentation+300_GTV-1.nii.gz   \n",
       "LUNG1-005  LUNG1-005-Segmentation+300_GTV-1.nii.gz   \n",
       "...                                            ...   \n",
       "LUNG1-418  LUNG1-418-Segmentation+300_GTV-1.nii.gz   \n",
       "LUNG1-419  LUNG1-419-Segmentation+300_GTV-1.nii.gz   \n",
       "LUNG1-420  LUNG1-420-Segmentation+300_GTV-1.nii.gz   \n",
       "LUNG1-421  LUNG1-421-Segmentation+300_GTV-1.nii.gz   \n",
       "LUNG1-422  LUNG1-422-Segmentation+300_GTV-1.nii.gz   \n",
       "\n",
       "                                                         COM   \n",
       "LUNG1-001  [((82.30074532053526, -201.48105435025894, -45...  \\\n",
       "LUNG1-002  [((-74.47025678716594, 16.355618635968504, -18...   \n",
       "LUNG1-003  [((47.42720699680901, -2.4607800757946747, -12...   \n",
       "LUNG1-004  [((59.82698099398604, 80.81240635855703, -557....   \n",
       "LUNG1-005  [((-58.78786734478716, 5.099882393388968, -15....   \n",
       "...                                                      ...   \n",
       "LUNG1-418  [((57.32439171943225, -145.95976964605273, -40...   \n",
       "LUNG1-419  [((-76.55753803907983, -207.93668661304113, -4...   \n",
       "LUNG1-420  [((54.15286421869259, -121.5744590908783, -519...   \n",
       "LUNG1-421  [((59.817097819498265, -168.61503094308367, -4...   \n",
       "LUNG1-422  [((-26.546376208612504, -145.0336046886111, -4...   \n",
       "\n",
       "           Number of lesions  \n",
       "LUNG1-001                  1  \n",
       "LUNG1-002                  1  \n",
       "LUNG1-003                  1  \n",
       "LUNG1-004                  1  \n",
       "LUNG1-005                  1  \n",
       "...                      ...  \n",
       "LUNG1-418                  3  \n",
       "LUNG1-419                  1  \n",
       "LUNG1-420                  1  \n",
       "LUNG1-421                  1  \n",
       "LUNG1-422                  1  \n",
       "\n",
       "[420 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Calculating the center of masses of lesions. This cell will take a while to compute\"\"\"\n",
    "\n",
    "# Image files for globbing pids\n",
    "files = [str(r.name) for r in img_dir.glob(\"*.nii.gz\")]\n",
    "pids = get_unique_IDs(files, idregpat)\n",
    "\n",
    "# exclude\n",
    "for p in exclude_pids:\n",
    "    if p in pids:\n",
    "        pids.remove(p)\n",
    "\n",
    "# create the id mapping\n",
    "img_list, tar_list = load_supervised_pair_by_IDs(str(img_dir), str(seg_dir), pids, globber=idregpat)\n",
    "img_list = pd.Series(data=img_list, index=pids, name='Images')\n",
    "tar_list = pd.Series(data=tar_list, index=pids, name='Segmentations')\n",
    "df_idmappings = pd.concat([img_list, tar_list], axis=1)\n",
    "\n",
    "# for each row, get center of masses\n",
    "com_series = pd.Series(name='COM', dtype=str)\n",
    "num_of_label_series = pd.Series(name='Number of lesions', dtype=int)\n",
    "for key, seg_file in df_idmappings['Segmentations'].items():\n",
    "    _seg_path = seg_dir.joinpath(seg_file)\n",
    "    _seg = sitk.ReadImage(str(_seg_path))\n",
    "    _seg_conn = get_connected_bodies(_seg)\n",
    "    \n",
    "    num_of_labels = len(_seg_conn)\n",
    "    _com_list = []\n",
    "    for _sc in _seg_conn:\n",
    "        _com = get_cent_of_mass(_sc)\n",
    "        _bounding_box = get_bounding_box(_sc)\n",
    "        _com_list.append((_com, _bounding_box))\n",
    "    com_series[key] = _com_list\n",
    "    num_of_label_series[key] = len(_seg_conn)\n",
    "    \n",
    "df = pd.concat([df_idmappings, com_series, num_of_label_series], axis=1)\n",
    "mdprint(\"# Center of masses\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7861d5c",
   "metadata": {},
   "source": [
    "## Performing the resampling\n",
    "\n",
    "Note that the output is very long and was discarded. As mentioned before the output patches extracted from the CT and the segmentation are available on request. As random sampling was invovled, you will not obtain the exact same output as us if you run this code alone. To allow reproducing our results, we also provide our sampled rotation matrices inform of `sitk.Transform` files. We do stress, however, that even if you redo the experiment with different sampled rotation, you will still find similar observation as we reported in the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe2aa7ff8effa3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the images \n",
    "selected_img, selected_seg = load_supervised_pair_by_IDs(str(img_dir), str(seg_dir), df.index, globber=idregpat)\n",
    "\n",
    "# Perform rotation and show the segmentations\n",
    "output_dir = data_root.joinpath(\"10.WaveletStudyData/\")\n",
    "imgpatch_outdir = output_dir.joinpath(\"A.ImgPatches\")\n",
    "segpatch_outdir = output_dir.joinpath(\"B.SegPatches\")\n",
    "imgpatch_outdir.mkdir(exist_ok=True, parents=True)\n",
    "segpatch_outdir.mkdir(exist_ok=True)\n",
    "for _pid, _img_p, _seg_p in zip(df.index, selected_img, selected_seg):\n",
    "    print(_pid)\n",
    "    _img = sitk.ReadImage(str(img_dir.joinpath(_img_p)))\n",
    "    _seg = sitk.ReadImage(str(seg_dir.joinpath(_seg_p)))\n",
    "    num_of_lesions = df.loc[_pid]['Number of lesions']\n",
    "    if num_of_lesions > 1:\n",
    "        _seg_conn = get_connected_bodies(_seg)\n",
    "        if len(_seg_conn) != num_of_lesions:\n",
    "            raise IndexError(f\"Number of segmentation components specified is incorrect for {_pid}: {_seg_p}\")\n",
    "        for i, _sc in enumerate(_seg_conn):\n",
    "            _new_pid = _pid + f'-{chr(i + 65)}'\n",
    "            print(_new_pid)\n",
    "            _img_out, _seg_out = resample_to_segment_bbox(_img_out, _sc, padding=10)\n",
    "            _imgfname = imgpatch_outdir.joinpath(f\"{_new_pid}_R0.nii.gz\")\n",
    "            _segfname = segpatch_outdir.joinpath(f\"{_new_pid}_R0.nii.gz\")\n",
    "            if _imgfname.is_file():\n",
    "                print(\"Skipping R0...\")\n",
    "            else:\n",
    "                sitk.WriteImage(_img_out, str(_imgfname))\n",
    "                sitk.WriteImage(_seg_out, str(_segfname))\n",
    "            for deg in rotations:\n",
    "                print(deg)\n",
    "                _imgfname = imgpatch_outdir.joinpath(f\"{_new_pid}_R{deg}.nii.gz\")\n",
    "                _segfname = segpatch_outdir.joinpath(f\"{_new_pid}_R{deg}.nii.gz\")\n",
    "                if _imgfname.is_file():\n",
    "                    continue\n",
    "                \n",
    "                _transform = rotations[deg][_new_pid]\n",
    "                _img_out = resample_image(_img, _transform)\n",
    "                _seg_out = resample_image(_sc, _transform)\n",
    "                _img_out, _seg_out = resample_to_segment_bbox(_img_out, _seg_out, padding=10)\n",
    "                \n",
    "                # Write image \n",
    "                sitk.WriteImage(_img_out, str(_imgfname))\n",
    "                sitk.WriteImage(_seg_out, str(_segfname))\n",
    "    else:    \n",
    "        _img_out, _seg_out = resample_to_segment_bbox(_img_out, _seg, padding=10)\n",
    "        _imgfname = imgpatch_outdir.joinpath(f\"{_new_pid}_R0.nii.gz\")\n",
    "        _segfname = segpatch_outdir.joinpath(f\"{_new_pid}_R0.nii.gz\")\n",
    "        if _imgfname.is_file():\n",
    "            print(\"Skipping R0...\")\n",
    "        else:\n",
    "            sitk.WriteImage(_img_out, str(_imgfname))\n",
    "            sitk.WriteImage(_seg_out, str(_segfname))   \n",
    "        for deg in rotations:\n",
    "            _imgfname = imgpatch_outdir.joinpath(f\"{_pid}_R{deg}.nii.gz\")\n",
    "            _segfname = segpatch_outdir.joinpath(f\"{_pid}_R{deg}.nii.gz\")\n",
    "            if _imgfname.is_file():\n",
    "                print(\"Skipping...\")\n",
    "                continue\n",
    "            \n",
    "            _transform = rotations[deg][_pid]\n",
    "            _img_out = resample_image(_img, _transform)\n",
    "            _seg_out = resample_image(_seg, _transform)\n",
    "            _img_out, _seg_out = resample_to_segment_bbox(_img_out, _seg_out, padding=10)\n",
    "\n",
    "\n",
    "            # Write image \n",
    "            sitk.WriteImage(_img_out, str(_imgfname))\n",
    "            sitk.WriteImage(_seg_out, str(_segfname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
